{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47995d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b11420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9fce78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d3452b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986ab29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8144c8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40933933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dacf2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a tatally imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4c5201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c47ce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Amount', ylabel='Density'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aad86b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time is here of no use\n",
    "df.drop('Time', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdef65bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "257cc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the features and labels\n",
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06b5b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now splitting into train and test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c242c5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227845, 29), (56962, 29), (227845,), (56962,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a0c7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standardizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dca5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a602202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "210c734d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train data:  0.9993109350655051\n",
      "Accuracy score of test data:  0.9991573329588147\n",
      "Confusion matrix of test data : \n",
      " [[56861    13]\n",
      " [   35    53]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56874\n",
      "           1       0.80      0.60      0.69        88\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.90      0.80      0.84     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "train_pred = lr.predict(X_train_scaled)\n",
    "test_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "print('Accuracy score of train data: ' ,accuracy_score(y_train, train_pred))\n",
    "print('Accuracy score of test data: ' ,accuracy_score(y_test, test_pred))\n",
    "\n",
    "print(\"Confusion matrix of test data : \\n\",confusion_matrix(y_test, test_pred))\n",
    "print(\"Classification report: \\n\", classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85ad237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train data:  1.0\n",
      "Accuracy score of test data:  0.9995611109160493\n",
      "Confusion matrix of test data : \n",
      " [[56870     4]\n",
      " [   21    67]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56874\n",
      "           1       0.94      0.76      0.84        88\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.88      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "train_pred = rf.predict(X_train_scaled)\n",
    "test_pred = rf.predict(X_test_scaled)\n",
    "\n",
    "print('Accuracy score of train data: ' ,accuracy_score(y_train, train_pred))\n",
    "print('Accuracy score of test data: ' ,accuracy_score(y_test, test_pred))\n",
    "\n",
    "print(\"Confusion matrix of test data : \\n\",confusion_matrix(y_test, test_pred))\n",
    "print(\"Classification report: \\n\", classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7812494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=10)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32f4e1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    227441\n",
       "1    227441\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train_res)['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "067255de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  intercept_scaling : float, default=1\n",
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train data:  0.9589739756684151\n",
      "Accuracy score of test data:  0.9824971033320459\n",
      "Confusion matrix of test data : \n",
      " [[55889   985]\n",
      " [   12    76]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56874\n",
      "           1       0.07      0.86      0.13        88\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.54      0.92      0.56     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_res, y_train_res.ravel())\n",
    "train_pred = lr.predict(X_train_res)\n",
    "test_pred = lr.predict(X_test_scaled)\n",
    "\n",
    "print('Accuracy score of train data: ' ,accuracy_score(y_train_res, train_pred))\n",
    "print('Accuracy score of test data: ' ,accuracy_score(y_test, test_pred))\n",
    "\n",
    "print(\"Confusion matrix of test data : \\n\",confusion_matrix(y_test, test_pred))\n",
    "print(\"Classification report: \\n\", classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72f90e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now building the simple neural network\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3722a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = X_train_res.shape[1]\n",
    "epochs = 50\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim = dimension, activation = 'relu'),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23ede845",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1fa08204",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7108/7108 [==============================] - 33s 5ms/step - loss: 0.0474 - accuracy: 0.9876 - val_loss: 0.0203 - val_accuracy: 0.9955\n",
      "Epoch 2/50\n",
      "7108/7108 [==============================] - 33s 5ms/step - loss: 0.0255 - accuracy: 0.9946 - val_loss: 0.0152 - val_accuracy: 0.9977\n",
      "Epoch 3/50\n",
      "7108/7108 [==============================] - 40s 6ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 0.0281 - val_accuracy: 0.9938\n",
      "Epoch 4/50\n",
      "7108/7108 [==============================] - 39s 5ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.0294 - val_accuracy: 0.9930\n",
      "Epoch 5/50\n",
      "7108/7108 [==============================] - 39s 5ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0170 - val_accuracy: 0.9974\n",
      "Epoch 6/50\n",
      "7108/7108 [==============================] - 40s 6ms/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.0247 - val_accuracy: 0.9956\n",
      "Epoch 7/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.0224 - val_accuracy: 0.9961\n",
      "Epoch 8/50\n",
      "7108/7108 [==============================] - 44s 6ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0148 - val_accuracy: 0.9990\n",
      "Epoch 9/50\n",
      "7108/7108 [==============================] - 42s 6ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0152 - val_accuracy: 0.9984\n",
      "Epoch 10/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0175 - val_accuracy: 0.9986\n",
      "Epoch 11/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0605 - val_accuracy: 0.9914\n",
      "Epoch 12/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0185 - val_accuracy: 0.9974\n",
      "Epoch 13/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0158 - val_accuracy: 0.9986\n",
      "Epoch 14/50\n",
      "7108/7108 [==============================] - 44s 6ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0223 - val_accuracy: 0.9970\n",
      "Epoch 15/50\n",
      "7108/7108 [==============================] - 42s 6ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0178 - val_accuracy: 0.9984\n",
      "Epoch 16/50\n",
      "7108/7108 [==============================] - 42s 6ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0204 - val_accuracy: 0.9977\n",
      "Epoch 17/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0161 - val_accuracy: 0.9989\n",
      "Epoch 18/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0171 - val_accuracy: 0.9991\n",
      "Epoch 19/50\n",
      "7108/7108 [==============================] - 46s 7ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0185 - val_accuracy: 0.9985\n",
      "Epoch 20/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0202 - val_accuracy: 0.9985\n",
      "Epoch 21/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0198 - val_accuracy: 0.9988\n",
      "Epoch 22/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0213 - val_accuracy: 0.9987\n",
      "Epoch 23/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0208 - val_accuracy: 0.9989\n",
      "Epoch 24/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0219 - val_accuracy: 0.9989\n",
      "Epoch 25/50\n",
      "7108/7108 [==============================] - 53s 7ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0198 - val_accuracy: 0.9991\n",
      "Epoch 26/50\n",
      "7108/7108 [==============================] - 48s 7ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0217 - val_accuracy: 0.9985\n",
      "Epoch 27/50\n",
      "7108/7108 [==============================] - 31s 4ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0256 - val_accuracy: 0.9976\n",
      "Epoch 28/50\n",
      "7108/7108 [==============================] - 46s 7ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0344 - val_accuracy: 0.9966\n",
      "Epoch 29/50\n",
      "7108/7108 [==============================] - 31s 4ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0214 - val_accuracy: 0.9987\n",
      "Epoch 30/50\n",
      "7108/7108 [==============================] - 33s 5ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0220 - val_accuracy: 0.9989\n",
      "Epoch 31/50\n",
      "7108/7108 [==============================] - 40s 6ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0210 - val_accuracy: 0.9991\n",
      "Epoch 32/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0204 - val_accuracy: 0.9991\n",
      "Epoch 33/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0226 - val_accuracy: 0.9992\n",
      "Epoch 34/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0218 - val_accuracy: 0.9991\n",
      "Epoch 35/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0293 - val_accuracy: 0.9979\n",
      "Epoch 36/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0224 - val_accuracy: 0.9990\n",
      "Epoch 37/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0231 - val_accuracy: 0.9992\n",
      "Epoch 38/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0253 - val_accuracy: 0.9986\n",
      "Epoch 39/50\n",
      "7108/7108 [==============================] - 46s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0245 - val_accuracy: 0.9990\n",
      "Epoch 40/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0233 - val_accuracy: 0.9993\n",
      "Epoch 41/50\n",
      "7108/7108 [==============================] - 46s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0251 - val_accuracy: 0.9989\n",
      "Epoch 42/50\n",
      "7108/7108 [==============================] - 47s 7ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0249 - val_accuracy: 0.9989\n",
      "Epoch 43/50\n",
      "7108/7108 [==============================] - 39s 5ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0262 - val_accuracy: 0.9983\n",
      "Epoch 44/50\n",
      "7108/7108 [==============================] - 52s 7ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0267 - val_accuracy: 0.9985\n",
      "Epoch 45/50\n",
      "7108/7108 [==============================] - 44s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0255 - val_accuracy: 0.9991\n",
      "Epoch 46/50\n",
      "7108/7108 [==============================] - 46s 7ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0288 - val_accuracy: 0.9983\n",
      "Epoch 47/50\n",
      "7108/7108 [==============================] - 43s 6ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0288 - val_accuracy: 0.9985\n",
      "Epoch 48/50\n",
      "7108/7108 [==============================] - 47s 7ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0249 - val_accuracy: 0.9989\n",
      "Epoch 49/50\n",
      "7108/7108 [==============================] - 45s 6ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0260 - val_accuracy: 0.9989\n",
      "Epoch 50/50\n",
      "7108/7108 [==============================] - 44s 6ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0262 - val_accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc4bc4a020>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_res, y_train_res, validation_data = (X_test, y_test), epochs= epochs, verbose = 1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3977fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train_res)\n",
    "test_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c00f7bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6142360e-26],\n",
       "       [1.4441124e-33],\n",
       "       [0.0000000e+00],\n",
       "       ...,\n",
       "       [9.9999976e-01],\n",
       "       [9.9990571e-01],\n",
       "       [9.9998844e-01]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a5058733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = (train_pred[:,0] > 0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4622e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = (test_pred[:, 0] > 0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3489276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train data:  0.9997252034593587\n",
      "Accuracy score of test data:  0.998156665847407\n",
      "Confusion matrix of test data : \n",
      " [[56819    55]\n",
      " [   50    38]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56874\n",
      "           1       0.41      0.43      0.42        88\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.70      0.72      0.71     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of train data: ' ,accuracy_score(y_train_res, train_pred))\n",
    "print('Accuracy score of test data: ' ,accuracy_score(y_test, test_pred))\n",
    "\n",
    "print(\"Confusion matrix of test data : \\n\",confusion_matrix(y_test, test_pred))\n",
    "print(\"Classification report: \\n\", classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e098b311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
